# CBIB Ubuntu Server Manual

| version | author | date       | diff  | other          |
| ------- | ------ | ---------- | ----- | -------------- |
| V1.0    | 王彬   | 2018.09.06 | Setup | initialization |

---

[TOC]

## 前言

​       此指导书作为CBIB实验室公用Ubuntu服务器指导资料，包含但不局限于深度学习环境搭建、服务器运维、服务器日常维修、硬件维护、问题定位以及解决措施，仅供参考。**除此之外还配备常见FAQ以及解决方案**，见[README.md](./README.md)。希望以此传承下去，为后续师兄弟减少环境搭建工作量，节约学习时间。

**请历届管理员严格把守以下规则：**

-  服务其ip地址不得以任何形式对外泄露
- 不得将服务器账号租、借给实验室意外人员
- 不使用GPU（仅占用CPU）的项目不得使用服务器
- 实验室老成员毕业离校后，及时回收账号
- 同一项目同一程序一次不得使用超过4块GPU，特殊情况除外
- 任何人不得私自删除、升级**公用库**（cuda、cudnn、tensorflow、keras、pytorch、caffa等），需经过管理员和大家一致同意后方可升级
- 每人限制一个服务器账号，不使用远程桌面（或使用频率低于2次/天）的用户，远程桌面应该处于常关状态
- 除管理员和负责人(金人超老师)以外，任何人不得使用root登录，root密码不得向任何人泄露
- 服务器机房每天必须检查一次，确保空调处于开启状态，室内温度不得超过40度
- 每隔一段时间要检查服务器机架后侧电线，防止温度过高造成电线老化漏电

----

此项目自2018.9.6发起，手册开源于github，由每一届服务器运维管理员负责维护。

> 2017.9~2018.9   管理员codewang， github地址<https://github.com/codewanghust/CBIB_Server_Manual>

---



## 第一章  服务器介绍

​      **Note：**后文中Linux发行版特指Ubuntu.本手册只提供命令行操作指导，不提供图像界面操作指导。

### 1.1 硬件

​       实验室目前共2台大服务器（10-GPU），2台小服务器（2-GPU）。其硬件配置如表1-1所示。

| 服务器编号 |   俗名    | GPU数量 |       GPU型号       | 显存 | 内存  | 硬盘 |                           CPU型号                            | 负责人 |
| :--------: | :-------: | :-----: | :-----------------: | :--: | :---: | :--: | :----------------------------------------------------------: | :----: |
|     1      | 老服务器  |   10    | GeForce GTX 1080 Ti | 12GB | 128GB | 12TB | `Intel(R) Xeon(R) CPU E5-2683 v3 @ 2.00GHz（2CPU-28核-64bit）` | 曹海潮 |
|     2      | 新服务器  |   10    | GeForce GTX 1080 Ti | 12GB | 128GB | 4TB  | `Intel(R) Xeon(R) CPU E5-2683 v3 @ 2.00GHz（2CPU-28核-64bit）` |  王彬  |
|     3      | 小服务器1 |    2    | GeForce GTX 1080 Ti | 12GB | 64GB  | 2TB  | `Intel(R) Xeon(R) CPU E5-2603 v4 @ 1.70GHz (1GPU-6核-64bit)` |  王彬  |
|     4      | 小服务器2 |         | GeForce GTX 1080 Ti | 12GB | 64GB  | 2TB  | `Intel(R) Xeon(R) CPU E5-2603 v4 @ 1.70GHz (1GPU-6核-64bit)` | 陆建国 |

<center> 表1-1 服务器硬件配置表 </center>

其中：

- 1号**老服务器**位于机房-服务器机架从上往下第一台（无外接显示器，无键鼠，与2号公用）
- 2号**新服务器**位于机房-服务器机架从上往下第二台（有外接显示器，有键鼠）
- 3号**小服务器1**位于实验室-进门第4排-右数4号桌（有外接显示器，有键鼠）
- 4号**小服务器2**位于机房-进门空调旁边（无外接显示器，无键鼠）

### 1.2 软件

​        软件配置涉及到大家的深度学习平台，格外重要。请管理员及时维护此表（表1-2），一旦出现私自更新、删除公用库可按照此表进行恢复。**这里只统计公用数据库，公用库，公用应用程序, \*表示未统计项，或不重要**

|     软件名称     |           1号            |           2号            |                3号                |                 4号                 | 表项维护人@维护日期 |
| :--------------: | :----------------------: | :----------------------: | :-------------------------------: | :---------------------------------: | :-----------------: |
|       `OS`       | `Ubuntu LTS 14.04(出厂)` | `Ubuntu LTS 14.04(出厂)` | `Ubuntu LTS 16.04  (王彬@2017.6)` | `Ubuntu LTS 16.04（陆建国@2017.6）` | `codewang@2017.9.6` |
|      `CUDA`      |          `9.0`           |          `8.0`           |               `9.0`               |                `9.0`                | `codewang@2017.9.6` |
|     `cudnn`      |           `*`            |           `*`            |               `8.5`               |                 `*`                 | `codewang@2017.9.6` |
| `nvidia-driver`  |        `384.130`         |         `384.69`         |             `384.130`             |                 `*`                 | `codewang@2017.9.6` |
|    `python3`     |         `3.4.3`          |         `3.4.3`          |              `3.6.5`              |                 `*`                 | `codewang@2017.9.6` |
| `Tensorflow`-gpu |         `1.3.0`          |         `1.4.0`          |              `1.8.0`              |                 `*`                 | `codewang@2017.9.6` |
|  `Tensorboard`   |         `0.1.8`          |         `0.4.0`          |              `1.8.0`              |                 `*`                 | `codewang@2017.9.6` |
|     `Keras`      |         `2.0.8`          |         `2.1.6`          |              `2.2.0`              |                 `*`                 | `codewang@2017.9.6` |
|    `Pytorch`     |           `无`           |         `0.1.0`          |                `*`                |                 `*`                 | `codewang@2017.9.6` |
|     `Caffa`      |           `*`            |           `*`            |               `无`                |                 `*`                 | `codewang@2017.9.6` |
|     `Theano`     |           `*`            |         `1.0.2`          |               `无`                |                 `*`                 | `codewang@2017.9.6` |
|     `Mxnet`      |           `*`            |      `1.1.0.post0`       |               `无`                |                 `*`                 | `codewang@2017.9.6` |
|    `xgboost`     |         `0.6a2`          |          `0.71`          |               `无`                |                 `*`                 | `codewang@2017.9.6` |
|    `ipython`     |         `6.2.1`          |         `6.2.1`          |              `6.4.0`              |                 `*`                 | `codewang@2017.9.6` |
|     `Cython`     |         `0.27.3`         |         `0.27.3`         |             `0.28.2`              |                 `*`                 | `codewang@2017.9.6` |

<center> 表1-2 服务器软件配置表 </center>

### 1.3 IP地址

IP地址是向学校申请的固定IP地址，如表1-3所示，校内任何地方均可以访问。**切记不可将服务IP地址告诉他人。**

| 编号 |     IP地址      |
| :--: | :-------------: |
| 1号  | xxx.xxx.xxx.253 |
| 2号  | xxx.xxx.xxx.232 |
| 3号  | xxx.xxx.xxx.226 |
| 4号  | xxx.xxx.xxx.225 |

<center> 表1-3 服务器IP配置表 </center> 

---



## 第二章 服务器配置

本章内容包括：

- 如何安装cuda、cudnn、tensorflow-gpu等深度学习框架，以及其配置过程
- 常用软件安装配置
- 固定IP配置
- 远程桌面配置<需配合第三章 Linux运维，可先阅读第三章>

### 2.1 深度学习框架配置

​       由于实验室项目不尽相同，不同的项目组可能会使用不同的深度学习框架，管理员只需用维护tensorflow和keras即可。但是cuda、cudnn是所有框架公用的，所以升级和维护需要实现与各项目组沟通协调。目前实验室所使用的深度学习框架包括：`keras with tensorflow-backend`(刘老师、马老师项目组)、`caffa`（金老师项目组）、`matlab`（许老师项目组）、`other`，下面主要介绍cudnn、cuda以及tensorflow和keras的安装配置。

#### 2.1.1 深度学习库依赖关系

​       我们知道CPU也好、GPU也好、硬盘、内存都是物理设备都属于硬件，那么操作系统或者计算机软件想要使用这些硬件，就需要驱动程序，这和Window是一样的。（虽然windows上有许多设备是免驱的，但是实质上他们使用的是公用驱动，万能驱动。比如鼠标、蓝牙键盘等，其实他们都是使用默认的USB设备驱动程序，所以可以免驱），所以我们想要使用GPU首先需要安装**驱动程序**。

​       除此之外，tensorflow这样的深度学习框架也不可能直接和GPU驱动程序打交道，不然tensorflow的软件体量就太大了，所以NVIDIA公司为这些上层应用软件提供了一些辅助程序，称之为**cuda**和**cudnn**。

​       然后就是我们熟悉的深度学习框架了，比如tensorflow、pytorch、mxnet、caffa等,**注意，Keras严格意义上来说并不是深度学习框架，它是以tensorflow或者theaon后后端的高级封装API库。**下面我们用一副图来了解它们的关系。如图2-1所示：

![软件库依赖关系](images/arch.png)

<center>图2-1 深度学习库依赖关系</center>





---



## 第三章 Linux运维



---



## 第四章 服务器管理

